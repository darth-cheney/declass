{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Gensim example\n",
      "\n",
      "* The [gensim tutorial](http://radimrehurek.com/gensim/tut1.html) shows you many ways of doing things...and gives reasons and explanations.\n",
      "* This notebook gives a step-by-step cookbook that will work if have a directory structure with flat files"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---\n",
      "\n",
      "## Set up\n",
      "\n",
      "---"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "\n",
      "import pandas as pd\n",
      "import matplotlib.pylab as plt\n",
      "\n",
      "#import logging\n",
      "#logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
      "from gensim import corpora, models, similarities\n",
      "import gensim\n",
      "\n",
      "from jrl_utils.src import nlp\n",
      "from declass.utils import text_processors, filefilter, gensim_helpers"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 498
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "reload(text_processors)\n",
      "reload(filefilter)\n",
      "reload(gensim_helpers)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 519,
       "text": [
        "<module 'declass.utils.gensim_helpers' from '/home/langmore/lib/declass/utils/gensim_helpers.pyc'>"
       ]
      }
     ],
     "prompt_number": 519
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "###############################################################################           \n",
      "# Paths                                                                                   \n",
      "###############################################################################           \n",
      "# I use environment variables to set my base paths\n",
      "DATA = os.environ['DATA']                                                                 \n",
      "ME = os.environ['ME']                                                                     \n",
      "MYDATA = os.path.join(DATA, ME, 'ddrs-01')                                           \n",
      "RAW = os.path.join(MYDATA, 'raw')                                                         \n",
      "PROCESSED = os.path.join(MYDATA, 'processed')\n",
      "\n",
      "# You only need to set these paths...any way you can\n",
      "metafile_path = os.path.join(RAW, 'ddrs_meta.csv')\n",
      "text_base_path = os.path.join(RAW, 'ddrs')\n",
      "corpus_path = os.path.join(PROCESSED, 'corpus', 'ddrs-gensim.svmlight')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 520
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---\n",
      "\n",
      "## Making a dictionary and a corpus\n",
      "\n",
      "* In gensim, a *dictionary* stores the mapping between strings (e.g. the words in text) and their integer representation (tokenid).  This can be accessed via `dictionary.token2id`\n",
      "* The dictionary is a basic data structure that is used in many places in gensim\n",
      "* In gensim, a *corpus* is an object that streams *bag of word* representations of documents\n",
      "* In gensim, the bag of words are always lists of pairs $$[(tokenid_1, value_1),...,(tokenid_k, value_k)]$$ where $tokenid_j$ is an integer.\n",
      "\n",
      "---"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Limit analysis to these lines of the corpus\n",
      "# Set == None for no limit\n",
      "limit = 2000"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 521
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# The tokenizer turns strings of text into lists of tokens, e.g. ['hi', 'bye']\n",
      "tokenizer = text_processors.TokenizerBasic()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 522
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Define a TokenStreamer over a set of paths\n",
      "# This will read text from each path and return tokens\n",
      "path_iter = filefilter.get_paths_iter(text_base_path)\n",
      "token_stream = text_processors.TokenStreamer(tokenizer, paths=path_iter, limit=limit)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 523
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dictionary = corpora.Dictionary(token_stream)\n",
      "print dictionary"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Dictionary(22071 unique tokens)\n"
       ]
      }
     ],
     "prompt_number": 524
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Filter extreme words\n",
      "dictionary.filter_extremes()\n",
      "\n",
      "# Remove some words that occur less than 5 times from dict\n",
      "# low_freq_ids = [tokenid for tokenid, docfreq in dictionary.dfs.iteritems() if docfreq < 5]\n",
      "# dictionary.filter_tokens(low_freq_ids)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 531
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Compactify and save to disk\n",
      "# ALWAYS compactify since this removes gaps and allows for a decent matrix representation (useful later)\n",
      "dictionary.compactify()\n",
      "dictionary.save(os.path.join(PROCESSED, 'dict', 'ddrs.dict'))\n",
      "print dictionary"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Dictionary(5437 unique tokens)\n"
       ]
      }
     ],
     "prompt_number": 532
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Create and then serialize (save to disk in a compact format) a corpus\n",
      "corpus = gensim_helpers.TextFilesCorpus(tokenizer, dictionary, base_path=text_base_path, limit=limit)\n",
      "corpora.SvmLightCorpus.serialize(corpus_path, corpus)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 533
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Do some EDA on the dictionary\n",
      "\n",
      "* You could also modify the dictionary here"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "id2token = dict(dictionary.items())  # dictionary.id2token is not populated by default!!!\n",
      "words = pd.DataFrame(\n",
      "                {id2token[tokenid]: [tokenid, docfreq] \n",
      "                 for tokenid, docfreq in dictionary.dfs.iteritems()},\n",
      "                index=['tokenid', 'docfreq']).T"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 334
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "words = words.sort_index(by='docfreq', ascending=False)\n",
      "words.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>tokenid</th>\n",
        "      <th>docfreq</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>such</th>\n",
        "      <td> 37989</td>\n",
        "      <td> 193413</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>more</th>\n",
        "      <td>  1691</td>\n",
        "      <td> 189259</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>military</th>\n",
        "      <td> 62041</td>\n",
        "      <td> 185313</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>lbj</th>\n",
        "      <td> 71391</td>\n",
        "      <td> 176464</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>states</th>\n",
        "      <td> 13933</td>\n",
        "      <td> 175798</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 338,
       "text": [
        "          tokenid  docfreq\n",
        "such        37989   193413\n",
        "more         1691   189259\n",
        "military    62041   185313\n",
        "lbj         71391   176464\n",
        "states      13933   175798"
       ]
      }
     ],
     "prompt_number": 338
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Log plot of distribution shows rapidly decaying tail\n",
      "words.docfreq.apply(np.log10).hist(bins=200)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 336,
       "text": [
        "<matplotlib.axes.AxesSubplot at 0x159b9c90>"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD9CAYAAAC/fMwDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZTGH4uJSoTEAAAAASUVORK5CYII=\n",
       "text": [
        "<matplotlib.figure.Figure at 0x11e0dd0>"
       ]
      }
     ],
     "prompt_number": 336
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Simple topic modeling"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Load the corpus from disk \n",
      "# You should start all analysis with this step\n",
      "corpus = corpora.SvmLightCorpus(corpus_path)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 534
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## LSI"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lsi = models.LsiModel(corpus, id2word=dictionary, num_topics=2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 535
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lsi.print_topics(2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 536,
       "text": [
        "['0.364*\"soviet\" + 0.230*\"military\" + 0.163*\"more\" + 0.161*\"such\" + 0.150*\"defense\" + 0.149*\"economic\" + 0.145*\"secret\" + 0.142*\"force\" + 0.136*\"forces\" + 0.132*\"states\"',\n",
        " '-0.382*\"annuity\" + -0.356*\"under\" + -0.318*\"participant\" + -0.296*\"section\" + -0.295*\"shall\" + 0.243*\"soviet\" + -0.229*\"such\" + -0.172*\"spouse\" + -0.171*\"former\" + -0.153*\"service\"']"
       ]
      }
     ],
     "prompt_number": 536
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## LDA"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "num_topics = 5\n",
      "num_words = len(dictionary.items())\n",
      "alpha = None #np.log(2 + np.arange(num_topics))\n",
      "eta = None #np.log(2 + np.arange(num_words))\n",
      "lda = models.LdaModel(corpus, id2word=dictionary, num_topics=num_topics, passes=1, alpha=alpha, eta=eta, chunksize=4000)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 537
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i in range(num_topics):\n",
      "    print\n",
      "    print \"topic\", i\n",
      "    print lda.print_topic(i, topn=6)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "topic 0\n",
        "0.008*secret + 0.005*more + 0.005*soviet + 0.005*such + 0.005*government + 0.005*force\n",
        "\n",
        "topic 1\n",
        "0.006*soviet + 0.005*mr + 0.005*secret + 0.005*force + 0.004*more + 0.004*military\n",
        "\n",
        "topic 2\n",
        "0.009*secret + 0.008*force + 0.006*soviet + 0.005*military + 0.004*under + 0.004*forces\n",
        "\n",
        "topic 3\n",
        "0.008*secret + 0.006*soviet + 0.005*such + 0.004*government + 0.004*military + 0.004*force\n",
        "\n",
        "topic 4\n",
        "0.008*soviet + 0.007*military + 0.007*secret + 0.005*united + 0.005*states + 0.004*forces\n"
       ]
      }
     ],
     "prompt_number": 538
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Print the topic distribution for the first document in the corpus\n",
      "one_doc = corpus.docbyoffset(corpus.index[0])\n",
      "vec_lda = lda[one_doc]\n",
      "print vec_lda"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[(1, 0.88826497499193069), (2, 0.080181616078792803), (3, 0.028938203793304553)]\n"
       ]
      }
     ],
     "prompt_number": 542
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Look at similarity between one_doc and all the other docs in the corpus\n",
      "# MatrixSimilarity uses a regular matrix...not good for memory\n",
      "# See http://radimrehurek.com/gensim/tut3.html  for different similarity matrix types (e.g. sparse)\n",
      "#\n",
      "# Of course this doc is most similar (score = 1) with itself.\n",
      "index = similarities.MatrixSimilarity(lda[corpus])\n",
      "sims = index[vec_lda]\n",
      "print sims"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 0.99827141  0.49985555  0.03242936 ...,  0.          0.02787292\n",
        "  0.84950769]\n"
       ]
      }
     ],
     "prompt_number": 543
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Performance considerations\n",
      "\n",
      "* Walking through a directory structure and tokenizing every file is slow\n",
      "  * You can tokenize once (quickly) and then re-load these tokens\n",
      "\n",
      "* LDA is slow\n",
      "  * Not sure what to do...I am linked against MKL...maybe VW is the only way"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Quick parallel tokenization\n",
      "\n",
      "Use the command line utility `cmd/files_to_vw.py` to tokenize and save to a sparse format.  Use the `n_jobs` option to do this in parallel."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Quick (VW) corpus streaming\n",
      "\n",
      "1. Use `VWFormatter.sfile_to_token_iter()` to convert the sparse files to a stream of token lists.\n",
      "2. Convert this stream to a dictionary\n",
      "3. Modify the dictionary if necessary\n",
      "4. Create the stream once again\n",
      "5. Serialize into the sparse SvmLightCorpus\n",
      "\n",
      "Note that we store the original corpus in VW format since this is much richer than SvmLight.  In particular, you can use actual strings to save the tokens, rather than tokenid (as required by SvmLight)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vw_corpus_path = os.path.join(PROCESSED, 'corpus', 'ddrs-vw')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 323
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Build a dictionary from a sparse (VW) representation of a corpus\n",
      "# About 2x faster than tokenizing on the fly using the BasicTokenizer\n",
      "# Even faster if your tokenizer is slow\n",
      "token_stream = text_processors.VWFormatter().sfile_to_token_iter(vw_corpus_path)\n",
      "dictionary = corpora.Dictionary(token_stream)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 325
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "token_stream = text_processors.VWFormatter().sfile_to_token_iter(vw_corpus_path)\n",
      "\n",
      "class MyCorpus(object):\n",
      "    \"\"\"\n",
      "    A simple corpus built with a dictionary and a token stream. \n",
      "    \"\"\"\n",
      "    def __init__(self, dictionary, token_stream):\n",
      "        self.token_stream = token_stream\n",
      "        self.dictionary = dictionary\n",
      "    \n",
      "    def __iter__(self):\n",
      "        \"\"\"\n",
      "        This method returns an iterator.\n",
      "        This method is automatically called when you use MyCorpus in a for loop.  The returned value becomes the loop iterator.\n",
      "        \"\"\"\n",
      "        for token_list in token_stream:\n",
      "            yield self.dictionary.doc2bow(token_list)\n",
      "\n",
      "%timeit -n1 -r1 corpora.SvmLightCorpus.serialize(corpus_path, MyCorpus(dictionary, token_stream))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1 loops, best of 1: 5min 52s per loop\n"
       ]
      }
     ],
     "prompt_number": 340
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---\n",
      "\n",
      "# Scratch work\n",
      "\n",
      "---"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print dictionary"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Dictionary(1461280 unique tokens)\n"
       ]
      }
     ],
     "prompt_number": 328
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dictionary.filter_extremes?"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 329
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dictionary.filter_extremes(no_below=5, no_above=0.5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 330
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print dictionary"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Dictionary(100000 unique tokens)\n"
       ]
      }
     ],
     "prompt_number": 331
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dictionary.filter_extremes(no_above=0.3)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 332
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print dictionary"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Dictionary(99997 unique tokens)\n"
       ]
      }
     ],
     "prompt_number": 333
    }
   ],
   "metadata": {}
  }
 ]
}