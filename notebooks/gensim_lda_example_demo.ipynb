{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Gensim example\n",
      "\n",
      "* The [gensim tutorial](http://radimrehurek.com/gensim/tut1.html) shows you many ways of doing things...and gives reasons and explanations.\n",
      "* This notebook gives a step-by-step cookbook that will work if have a directory structure with flat files\n",
      "  * Use IPython's object introspection and help displays to learn about the objects created\n",
      "  * The custom classes are located in the `declass` repo, so you can also look at the source code."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---\n",
      "\n",
      "## Set up\n",
      "\n",
      "---"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "\n",
      "import pandas as pd\n",
      "import matplotlib.pylab as plt\n",
      "\n",
      "from gensim import corpora, models, similarities\n",
      "import gensim\n",
      "\n",
      "from declass.utils import text_processors, filefilter, gensim_helpers, nlp"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Every time you change the source code you need to reload it\n",
      "reload(text_processors)\n",
      "reload(filefilter)\n",
      "reload(gensim_helpers)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 2,
       "text": [
        "<module 'declass.utils.gensim_helpers' from '/home/langmore/lib/declass/declass/utils/gensim_helpers.pyc'>"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Set paths         \n",
      "# I use environment variables to set my base paths\n",
      "DATA = os.environ['DATA']                                                                 \n",
      "ME = os.environ['ME']                                                                     \n",
      "MYDATA = os.path.join(DATA, ME, 'ddrs-01')                                           \n",
      "RAW = os.path.join(MYDATA, 'raw')                                                         \n",
      "PROCESSED = os.path.join(MYDATA, 'processed')\n",
      "\n",
      "# You only need to set these paths below...any way you can\n",
      "metafile_path = os.path.join(RAW, 'ddrs_meta.csv')\n",
      "text_base_path = os.path.join(RAW, 'ddrs_nofoot')  # Read files made with the \"nofoot\" option\n",
      "corpus_path = os.path.join(PROCESSED, 'corpus', 'ddrs-gensim.svmlight')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Getting the files from the Database\n",
      "\n",
      "Use the command-line utility `declass/cmd/dump_ddrs_documents.py`.  \n",
      "\n",
      "* Try using it with the option `--limit 10` first.  This will allow you to quickly test its behavior.\n",
      "* Try getting all documents in raw form first with the `raw` option.  The database pull is the slowest part."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---\n",
      "\n",
      "## Making a dictionary and a corpus\n",
      "\n",
      "* In gensim, a *dictionary* stores the mapping between strings (e.g. the words in text) and their integer representation (tokenid).  This can be accessed via `dictionary.token2id`.  It also has a function `doc2bow` that transforms tokens to a *bag of words*.\n",
      "* In gensim, a *bag of words* is a list of tuples $$[(tokenid_1, value_1),...,(tokenid_k, value_k)]$$ where $tokenid_j$ is an integer, and $value_k$ is a real number.\n",
      "* In gensim, a *corpus* is an [iterable](http://stackoverflow.com/questions/9884132/understanding-pythons-iterator-iterable-and-iteration-protocols-what-exact) over *bag of words* representations of documents.\n",
      "\n",
      "---"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Limit analysis to these lines of the corpus.  This is very useful for learning.\n",
      "# Set == None for no limit.  Set to 5000 to finish in a reasonable amount of time.\n",
      "limit = 200"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# The tokenizer turns strings of text such as \"hi bye\" into lists of tokens, e.g. ['hi', 'bye']\n",
      "# You can add your own tokenizers to text_processors.  Give them the same API as TokenizerBasic.\n",
      "tokenizer = text_processors.TokenizerBasic()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Define a TokenStreamer over a set of paths\n",
      "# token_stream will read text from each path and return tokens\n",
      "path_iter = filefilter.get_paths(text_base_path, get_iter=True)\n",
      "token_stream = text_processors.TokenStreamer(tokenizer, paths=path_iter, limit=limit)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Convert the token stream into a dictionary\n",
      "# Note that nothing was read from disk until this point!  \n",
      "# Previously, we had simply defined iterators over files, \n",
      "# but we only here do we tell the iterators to start their iterations.\n",
      "dictionary = corpora.Dictionary(token_stream)\n",
      "print dictionary"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Dictionary(17811 unique tokens)\n"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Filter extreme words using the built-in method filter_extremes()\n",
      "dictionary.filter_extremes()\n",
      "\n",
      "# You can also do a custom filter, e.g.\n",
      "# Remove some words that occur less than 5 times from dict:\n",
      "# low_freq_ids = [tokenid for tokenid, docfreq in dictionary.dfs.iteritems() if docfreq < 5]\n",
      "# dictionary.filter_tokens(low_freq_ids)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Compactify and save to disk\n",
      "# ALWAYS compactify since this removes gaps and allows for a decent matrix representation (useful later)\n",
      "dictionary.compactify()\n",
      "dictionary.save(os.path.join(PROCESSED, 'dict', 'ddrs.dict'))\n",
      "print dictionary"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Dictionary(3666 unique tokens)\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Create and then serialize (save to disk in a compact format) a corpus\n",
      "corpus = gensim_helpers.TextFilesCorpus(tokenizer, dictionary, base_path=text_base_path, limit=limit)\n",
      "corpora.SvmLightCorpus.serialize(corpus_path, corpus)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Do some EDA on the dictionary\n",
      "\n",
      "* You could also modify the dictionary here"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "id2token = dict(dictionary.items())  # dictionary.id2token is not populated by default!!!\n",
      "words = pd.DataFrame(\n",
      "                {id2token[tokenid]: [tokenid, docfreq] \n",
      "                 for tokenid, docfreq in dictionary.dfs.iteritems()},\n",
      "                index=['tokenid', 'docfreq']).T"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "words = words.sort_index(by='docfreq', ascending=False)\n",
      "words.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>tokenid</th>\n",
        "      <th>docfreq</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>made</th>\n",
        "      <td> 3595</td>\n",
        "      <td> 97</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>general</th>\n",
        "      <td> 1748</td>\n",
        "      <td> 95</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>action</th>\n",
        "      <td> 1907</td>\n",
        "      <td> 93</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>department</th>\n",
        "      <td> 2695</td>\n",
        "      <td> 91</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>united</th>\n",
        "      <td> 2933</td>\n",
        "      <td> 91</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 12,
       "text": [
        "            tokenid  docfreq\n",
        "made           3595       97\n",
        "general        1748       95\n",
        "action         1907       93\n",
        "department     2695       91\n",
        "united         2933       91"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Log plot of distribution shows rapidly decaying tail\n",
      "words.docfreq.apply(np.log10).hist(bins=200)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 13,
       "text": [
        "<matplotlib.axes.AxesSubplot at 0x3c716d0>"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD9CAYAAACyYrxEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRCTNqdCLiKS5/wOYcFHLxZ/z3gAAAABJRU5ErkJggg==\n",
       "text": [
        "<matplotlib.figure.Figure at 0x3c5db50>"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Simple topic modeling"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Load the corpus from disk \n",
      "# You should start all analysis with this step\n",
      "corpus = corpora.SvmLightCorpus(corpus_path)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## LSI"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lsi = models.LsiModel(corpus, id2word=dictionary, num_topics=2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lsi.print_topics(2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 16,
       "text": [
        "['0.326*\"million\" + 0.164*\"government\" + 0.159*\"total\" + 0.154*\"fy\" + 0.153*\"foreign\" + 0.144*\"egypt\" + 0.137*\"year\" + 0.131*\"project\" + 0.108*\"new\" + 0.108*\"percent\"',\n",
        " '0.405*\"nsc\" + 0.283*\"staff\" + -0.281*\"million\" + 0.160*\"senior\" + 0.157*\"report\" + 0.146*\"council\" + 0.142*\"secretary\" + -0.140*\"fy\" + 0.138*\"memo\" + 0.138*\"action\"']"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## LDA"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "num_words = len(dictionary.items())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Standard settings\n",
      "alpha = None # same as alpha = 1\n",
      "eta = None  # same as eta = 1\n",
      "num_topics = 5"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Screwball alpha setting\n",
      "# pdf(topic) is peaked near 1 for topic 0, and uniform in topics 1 to 4\n",
      "# ...so topic 1 is the most likely topic.  See the histogram of df_corpus below\n",
      "alpha = [10, 1, 1, 1, 1]\n",
      "eta = None"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 79
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Screwball eta setting\n",
      "# pdf(word | topic) is peaked near 1 for word 0, and near 0 for the other words\n",
      "# so word 0 is the most likely word.  You can find \"word 0\" using dictionary.id2token[0] \n",
      "# See the topic printout below and you should find that word 0 is in every topic!\n",
      "alpha = None\n",
      "eta = np.r_[1000, 0.1 * np.ones(num_words - 1)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 80
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Train the LDA model\n",
      "lda = models.LdaModel(corpus, id2word=dictionary, num_topics=num_topics, passes=1, alpha=alpha, eta=eta, chunksize=4000)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Print the top 6 words for every topic\n",
      "for i in range(num_topics):\n",
      "    print\n",
      "    print \"topic\", i\n",
      "    print lda.print_topic(i, topn=6)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "topic 0\n",
        "0.010*secretary + 0.009*nsc + 0.009*mr + 0.008*defense + 0.007*security + 0.007*intelligence\n",
        "\n",
        "topic 1\n",
        "0.004*new + 0.003*party + 0.003*information + 0.003*two + 0.002*national + 0.002*during\n",
        "\n",
        "topic 2\n",
        "0.006*mr + 0.005*out + 0.004*secretary + 0.004*now + 0.003*meeting + 0.003*very\n",
        "\n",
        "topic 3\n",
        "0.007*government + 0.007*economic + 0.006*military + 0.006*political + 0.005*soviet + 0.005*communist\n",
        "\n",
        "topic 4\n",
        "0.009*forces + 0.007*air + 0.007*military + 0.006*force + 0.005*defense + 0.004*north"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Print the topic distribution for the first document in the corpus\n",
      "one_doc = corpus.docbyoffset(corpus.index[0])\n",
      "vec_lda = lda[one_doc]\n",
      "print vec_lda"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[(1, 0.98774353527979142)]\n"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Store the topic score for every doc in the corpus\n",
      "\n",
      "# Or without parallel_easy\n",
      "#df_corpus = pd.concat([pd.Series(dict(doc)) for doc in lda[corpus]], axis=1).fillna(0).T"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "making lda_corpus\n",
        "Making list\n"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Look at histograms of each topic over the corpus\n",
      "fig = df_corpus.hist()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Look at similarity between one_doc and all the other docs in the corpus\n",
      "# MatrixSimilarity uses a regular matrix...not good for memory\n",
      "# See http://radimrehurek.com/gensim/tut3.html  for different similarity matrix types (e.g. sparse)\n",
      "#\n",
      "# Of course this doc is most similar (score = 1) with itself.\n",
      "index = similarities.MatrixSimilarity(lda[corpus])\n",
      "doc_zero = corpus.docbyoffset(corpus.index[0])\n",
      "sims = index[lda[doc_zero]]\n",
      "print sims[:5]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Compare a new doc to the existing docs\n",
      "# This time, store the similarity in a pandas Series for easy plotting\n",
      "new_doc = dictionary.doc2bow(['hello', 'my', 'name', 'is', 'richard', 'nixon'])\n",
      "new_doc_sims = pd.Series(index[lda[new_doc]])\n",
      "fig = new_doc_sims.hist()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---\n",
      "\n",
      "# Performance considerations\n",
      "\n",
      "**Note**: Items in this section are experimental and the API may change faster than the above cells\n",
      "\n",
      "* Walking through a directory structure and tokenizing every file is slow\n",
      "  * You can tokenize once (quickly) and then re-load these tokens\n",
      "\n",
      "* LDA is slow\n",
      "  * Not sure what to do...I am linked against MKL...maybe VW is the only way\n",
      "  \n",
      "---"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Quick parallel tokenization\n",
      "\n",
      "Use the command line utility `cmd/files_to_vw.py` to tokenize and save to a sparse format.  Use the `n_jobs` option to do this in parallel.  Note that this utility requires the [parallel_easy](https://github.com/langmore/parallel_easy) library."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Quick (VW) corpus streaming\n",
      "\n",
      "1. Use `VWFormatter.sfile_to_token_iter()` to convert the sparse files to a stream of token lists.\n",
      "2. Convert this stream to a dictionary\n",
      "3. Modify the dictionary if necessary\n",
      "4. Create the stream once again\n",
      "5. Serialize into the sparse SvmLightCorpus\n",
      "\n",
      "Note that we store the original corpus in VW format since this is much richer than SvmLight.  In particular, you can use actual strings to save the tokens, rather than tokenid (as required by SvmLight)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vw_corpus_path = os.path.join(PROCESSED, 'corpus', 'ddrs-vw')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 323
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Build a dictionary from a sparse (VW) representation of a corpus\n",
      "# About 2x faster than tokenizing on the fly using the BasicTokenizer\n",
      "# Even faster if your tokenizer is slow\n",
      "token_stream = text_processors.VWFormatter().sfile_to_token_iter(vw_corpus_path)\n",
      "dictionary = corpora.Dictionary(token_stream)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 325
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Note:  This interface is experimental\n",
      "token_stream = text_processors.VWFormatter().sfile_to_token_iter(vw_corpus_path)\n",
      "\n",
      "class MyCorpus(object):\n",
      "    \"\"\"\n",
      "    A simple corpus built with a dictionary and a token stream. \n",
      "    \"\"\"\n",
      "    def __init__(self, dictionary, token_stream):\n",
      "        self.token_stream = token_stream\n",
      "        self.dictionary = dictionary\n",
      "    \n",
      "    def __iter__(self):\n",
      "        \"\"\"\n",
      "        This method returns an iterator.\n",
      "        This method is automatically called when you use MyCorpus in a for loop.  The returned value becomes the loop iterator.\n",
      "        \"\"\"\n",
      "        for token_list in token_stream:\n",
      "            yield self.dictionary.doc2bow(token_list)\n",
      "\n",
      "%timeit -n1 -r1 corpora.SvmLightCorpus.serialize(corpus_path, MyCorpus(dictionary, token_stream))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1 loops, best of 1: 5min 52s per loop\n"
       ]
      }
     ],
     "prompt_number": 340
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Make df_corpus quickly using parallel_easy\n",
      "# \n",
      "from parallel_easy.parallel_easy import base, pandas_easy\n",
      "\n",
      "def func(doc):\n",
      "    return pd.Series(dict(doc))\n",
      "print \"making lda_corpus\"\n",
      "lda_corpus = lda[corpus]\n",
      "print \"Making list\"\n",
      "lda_series_list = base.map_easy(func, lda_corpus, -1)\n",
      "df_corpus = pd.concat(lda_series_list, axis=1).fillna(0).T"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---\n",
      "\n",
      "# Scratch work\n",
      "\n",
      "---"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print dictionary"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Dictionary(1461280 unique tokens)\n"
       ]
      }
     ],
     "prompt_number": 328
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dictionary.filter_extremes?"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 329
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dictionary.filter_extremes(no_below=5, no_above=0.5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 330
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print dictionary"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Dictionary(100000 unique tokens)\n"
       ]
      }
     ],
     "prompt_number": 331
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dictionary.filter_extremes(no_above=0.3)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 332
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print dictionary"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Dictionary(99997 unique tokens)\n"
       ]
      }
     ],
     "prompt_number": 333
    }
   ],
   "metadata": {}
  }
 ]
}